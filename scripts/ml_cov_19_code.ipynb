{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YlWhTzU4uO9B"
      },
      "source": [
        "## 01 - Intro\n",
        "Machine Learning (ML) Project for CCO - 724 - Machine Learning (Aprendizado de Máquina) course of PPGCC UFSCAr [[link]](https://www.ppgcc.ufscar.br/pt-br/programa/estrutura-curricular/disciplinas-do-programa/cco-724-aprendizado-de-maquina)\n",
        "\n",
        " * Students: Gustavo das Neves Ubeda and Robson Rogério Dutra Pereira\n",
        " * Professor: Prof. Dr. Diego Furtado Silva\n",
        " * Dataset: Kaggle Covid-19 image dataset [[link]](https://www.kaggle.com/datasets/pranavraikokte/covid19-image-dataset) \n",
        " * Presentation Videos: Link [[1]](https://loom.com/share/5b2fd25db9974fd59cf1967a5a2b6f6c) and Link [[2]](https://youtu.be/3Eo-i8RRLeI) \n",
        "\n",
        "## 02 - About the dataset\n",
        "The dataset used throughout the experiment was provided by the University of Montreal for the COVID-19 detection using only chest X-rays. The dataset was made available already separated into training and test subsets, containing the following classes and their respective amounts of images:\n",
        "* Training partition:\n",
        "   * Patients with COVID-19: 111 images [Covid]\n",
        "   * Patients with Pneumonia: 70 images [Viral Pneumonia]\n",
        "   * Healthy patients: 70 images [Normal]\n",
        "\n",
        "* Test partition:\n",
        "   * Patients with COVID-19: 26 images [Covid]\n",
        "   * Patients with Pneumonia: 20 images [Viral Pneumonia]\n",
        "   * Healthy patients: 20 images [Normal]\n",
        "\n",
        "### Data balancing\n",
        "The analyzed dataset does not have balance for all classes, only patients with pneumonia and normal are balanced, and those with COVID-19 have more examples in the training and test samples. As this disparity is positive for the most important class (the detection of COVID-19), then techniques for balancing classes was not implemented.\n",
        "\n",
        "## 03 - Filepaths\n",
        "### Windows OS filepath\n",
        "* In our case, we are using:\n",
        "``` sh\n",
        "C:\\GitProjW\\ml_cov_19\\Covid19-dataset\\train\n",
        "C:\\GitProjW\\ml_cov_19\\Covid19-dataset\\train\\output\n",
        "C:\\GitProjW\\ml_cov_19\\Covid19-dataset\\test\n",
        "```\n",
        "\n",
        "* Wich are conveted on the Python code for:\n",
        "```python\n",
        "import sys, time, os, datetime, glob\n",
        "\n",
        "dir_train = os.path.join('c:\\\\','GitProjW','ml_cov_19','Covid19-dataset','train')\n",
        "dir_aug = os.path.join('c:\\\\','GitProjW','ml_cov_19','Covid19-dataset','train','output')\n",
        "dir_test = os.path.join('c:\\\\','GitProjW','ml_cov_19','Covid19-dataset','test')\n",
        "```\n",
        "\n",
        "### Linux Ubuntu OS filepath\n",
        "* The Python code '~'(home):\n",
        "```python\n",
        "import sys, time, os, datetime, glob\n",
        "\n",
        "dir_train = os.path.join('~','GitProjW','ml_cov_19','Covid19-dataset','train')\n",
        "dir_aug = os.path.join('~','GitProjW','ml_cov_19','Covid19-dataset','train','output')\n",
        "dir_test = os.path.join('~','GitProjW','ml_cov_19','Covid19-dataset','test')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OrxfvKUxxVe3"
      },
      "outputs": [],
      "source": [
        "import sys, time, os, datetime, glob\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray,rgba2rgb\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "\n",
        "# Image features lib\n",
        "from skimage.feature import hog\n",
        "\n",
        "# augmentation lib\n",
        "import Augmentor\n",
        "\n",
        "# Machine Learning modeling and avaliation\n",
        "from sklearn.ensemble import RandomForestClassifier # Trunk method Ensemble of Machine Learning\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Sys version) :|: 3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)] :|:\n",
            "(Python version) :#: 3.7.13 :#:\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "\n",
        "print(f\"(Sys version) :|: {sys.version} :|:\")\n",
        "os.system(\"which python\")\n",
        "print(f\"(Python version) :#: {python_version()} :#:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhbQxejEssXY",
        "outputId": "be2dd9c3-c859-4442-a102-72f12b7cc92c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\GitProjW\\ml_cov_19\\Covid19-dataset\\train\n",
            "c:\\GitProjW\\ml_cov_19\\Covid19-dataset\\train\\output\n",
            "c:\\GitProjW\\ml_cov_19\\Covid19-dataset\\test\n"
          ]
        }
      ],
      "source": [
        "# Datasets \n",
        "dir_train = os.path.join('c:\\\\','GitProjW','ml_cov_19','Covid19-dataset','train')\n",
        "print(dir_train)\n",
        "dir_aug = os.path.join('c:\\\\','GitProjW','ml_cov_19','Covid19-dataset','train','output')\n",
        "print(dir_aug)\n",
        "dir_test = os.path.join('c:\\\\','GitProjW','ml_cov_19','Covid19-dataset','test')\n",
        "print(dir_test)\n",
        "\n",
        "# Classes\n",
        "class_names = ['Covid', 'Viral Pneumonia', 'Normal']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SJYrq8Iey6tZ"
      },
      "outputs": [],
      "source": [
        "def read_process_img(dir_datasets, class_names):\n",
        "  # KDD definitions\n",
        "  class_list   = []\n",
        "  n_class_list = []\n",
        "  feature_list = []\n",
        "\n",
        "  # Datasets images reading\n",
        "  class_number = 0\n",
        "  for class_name in class_names:\n",
        "    # Linux OS filepath\n",
        "    # for img_name in os.listdir(f'{dir_datasets}/{class_name}'):\n",
        "    #   # print(\"ForImread:\\n{0}\".format(f'{dir_datasets}/{class_name}/{img_name}'))\n",
        "    #   img = imread(f'{dir_datasets}/{class_name}/{img_name}')\n",
        "\n",
        "    # Windows OS filepath\n",
        "    for img_name in os.listdir(f'{dir_datasets}\\{class_name}'):\n",
        "      # print(\"ForImread:\\n{0}\".format(f'{dir_datasets}\\{class_name}\\{img_name}'))\n",
        "      img = imread(f'{dir_datasets}\\{class_name}\\{img_name}')\n",
        "      # print(\"imgShape:\\n{0}\".format(img.shape))\n",
        "\n",
        "      # Black and white conversion\n",
        "      if len(img.shape) == 2:\n",
        "          img_gray = img\n",
        "      elif len(img.shape) == 3:\n",
        "          if img.shape[-1] == 4:\n",
        "              img_rgb = rgba2rgb(img)\n",
        "              img_gray = rgb2gray(img_rgb)\n",
        "          else:\n",
        "              img_gray = rgb2gray(img)\n",
        "\n",
        "      # Images resizing\n",
        "      r_img = resize(img_gray, (128, 128))\n",
        "\n",
        "      # Feature extration by HOG method\n",
        "      hog_feature, hog_img = hog(r_img, orientations=9,\n",
        "                                pixels_per_cell=(8, 8), cells_per_block=(2, 2),\n",
        "                                visualize=True)\n",
        "\n",
        "      # KDD data storage\n",
        "      class_list.append(class_name)\n",
        "      n_class_list.append(class_number)\n",
        "      feature_list.append(hog_feature)\n",
        "\n",
        "    class_number += 1\n",
        "\n",
        "  return feature_list, n_class_list, class_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXf4qv6cqALn",
        "outputId": "05b959c4-d9b2-411e-b35a-09cd87f8729a"
      },
      "outputs": [],
      "source": [
        "X_train,y_train,y_train_class=read_process_img(dir_train,class_names)\n",
        "X_test,y_test,y_test_class=read_process_img(dir_test,class_names)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 04 - Results of Standard Dataset\n",
        "\n",
        "After the training and the tests, we got the following results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVGQewOp-ayN",
        "outputId": "22cee33b-5f1d-4a49-a257-c08a2f61d81e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          Covid       0.76      0.96      0.85        26\n",
            "Viral Pneumonia       0.57      0.60      0.59        20\n",
            "         Normal       0.83      0.50      0.62        20\n",
            "\n",
            "       accuracy                           0.71        66\n",
            "      macro avg       0.72      0.69      0.69        66\n",
            "   weighted avg       0.72      0.71      0.70        66\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classificator = RandomForestClassifier(n_estimators=100, random_state=13)\n",
        "classificator.fit(X_train, y_train)\n",
        "\n",
        "# Class predition of test set\n",
        "y_predicted = classificator.predict(X_test)\n",
        "\n",
        "# Report model performance\n",
        "print(classification_report(y_test, y_predicted, target_names = class_names))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the cross validation was performed too:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1_JzuHPzsnF",
        "outputId": "0e965e81-533f-43a2-e143-ae2df66721a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV accuracy scores: [0.80769231 0.8        0.96       0.96       0.8        0.88\n",
            " 0.88       0.96       0.84       0.8       ]\n",
            "CV accuracy: 0.869 +/- 0.066\n"
          ]
        }
      ],
      "source": [
        "# Runs cross validation\n",
        "scores = cross_val_score(classificator, X=X_train, y=y_train, cv=10, n_jobs=1)\n",
        "\n",
        "print('CV accuracy scores: %s' % scores)\n",
        "\n",
        "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores),np.std(scores)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tYGUpVq97NMV"
      },
      "source": [
        "## 05 - Results with Dataset Augmentation\n",
        "### Augmentation\n",
        "Since it is possible to obtain better predictive results for Machine Learning (ML) models trained from larger databases, as seen in the course, the augmentation process was done to the training set to validate data augmentation hypothesis.\n",
        "\n",
        "After the augmentation, the training and the tests, we got the following results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qSXxX92j0nNC"
      },
      "outputs": [],
      "source": [
        "# Number of augmented images\n",
        "count_img = 0\n",
        "for cl in class_names:\n",
        "  try:\n",
        "    count_img += len(os.listdir(f'{dir_aug}/{cl}'))\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "if count_img < 502:\n",
        "  # Increase train set\n",
        "  p = Augmentor.Pipeline(dir_train)\n",
        "\n",
        "  p.rotate(probability=0.9, max_left_rotation=10, max_right_rotation=10) # Images rotation\n",
        "  p.zoom(probability=0.1, min_factor=1.1, max_factor=1.3) # Imagese zooming \n",
        "  p.sample(502) # Creating N new examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHqa0REV6BJY",
        "outputId": "6e4fb86c-f6a4-475c-8842-41291771b832"
      },
      "outputs": [],
      "source": [
        "X_aug, y_aug, y_aug_class = read_process_img(dir_aug, class_names)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After the augmentation, the training and the tests, we got the following results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZZ8BUl26tmq",
        "outputId": "80372179-11f1-490c-af1d-fd9c8432d983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          Covid       0.81      0.96      0.88        26\n",
            "Viral Pneumonia       0.52      0.55      0.54        20\n",
            "         Normal       0.71      0.50      0.59        20\n",
            "\n",
            "       accuracy                           0.70        66\n",
            "      macro avg       0.68      0.67      0.67        66\n",
            "   weighted avg       0.69      0.70      0.69        66\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classificator_aug = RandomForestClassifier(n_estimators=100, random_state=13)\n",
        "classificator_aug.fit(X_train + X_aug, y_train + y_aug)\n",
        "\n",
        "# Class predition of test set\n",
        "y_predicted_aug = classificator_aug.predict(X_test)\n",
        "\n",
        "# Report model performance\n",
        "print(classification_report(y_test, y_predicted_aug, target_names = class_names))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And also the cross validation was performed too"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSNdZUi7CVuG",
        "outputId": "4e03e064-c27b-48e3-c73e-d61433a39135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV accuracy scores: [0.92105263 0.88157895 0.89473684 0.81333333 0.88       0.89333333\n",
            " 0.85333333 0.88       0.89333333 0.86666667]\n",
            "CV accuracy: 0.878 +/- 0.027\n"
          ]
        }
      ],
      "source": [
        "# Runs cross validation\n",
        "scores_aug = cross_val_score(classificator_aug, X=(X_train + X_aug), y=(y_train + y_aug), cv=10, n_jobs=1)\n",
        "\n",
        "print('CV accuracy scores: %s' % scores_aug)\n",
        "\n",
        "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores_aug),np.std(scores_aug)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UTAow_b14Kig"
      },
      "source": [
        "## 06 - References\n",
        "- https://towardsdatascience.com/hog-histogram-of-oriented-gradients-67ecd887675f\n",
        "- https://stackoverflow.com/questions/58270129/convert-categorical-data-into-numerical-data-in-python\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
        "- https://augmentor.readthedocs.io/en/master/userguide/install.html"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
